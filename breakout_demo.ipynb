{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from   gym import envs\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acrobot-v1\n",
      "AirRaid-ram-v0\n",
      "AirRaid-ram-v3\n",
      "AirRaid-ramDeterministic-v0\n",
      "AirRaid-ramDeterministic-v3\n",
      "AirRaid-ramNoFrameskip-v0\n",
      "AirRaid-ramNoFrameskip-v3\n",
      "AirRaid-v0\n",
      "AirRaid-v3\n",
      "AirRaidDeterministic-v0\n",
      "AirRaidDeterministic-v3\n",
      "AirRaidNoFrameskip-v0\n",
      "AirRaidNoFrameskip-v3\n",
      "Alien-ram-v0\n",
      "Alien-ram-v3\n",
      "Alien-ramDeterministic-v0\n",
      "Alien-ramDeterministic-v3\n",
      "Alien-ramNoFrameskip-v0\n",
      "Alien-ramNoFrameskip-v3\n",
      "Alien-v0\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "#Printing first 20 environments\n",
    "[print(e) for e in sorted(envs.registry.env_specs.keys())[:20]] ; print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a breakout environment to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-20 12:27:17,768] Making new env: Breakout-v3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space      : Discrete(6)\n",
      "Observation space : Box(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "#Creating environment (with render)\n",
    "env = gym.make('Breakout-v3')\n",
    "\n",
    "#Showing action and observation space\n",
    "print('Action Space      : ' + str(env.action_space))\n",
    "print('Observation space : ' + str(env.observation_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it tells us that the agent can perform 6 different discrete action (don't move, move left, right, etc.) and these actions are defined by the vector [0:5]. To be honest, I am not sure what the various actions refer to, so it might be worth it to explore the outcome of each action value.\n",
    "\n",
    "The observation space is our box. where we see the agent playing (if render() is on).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "nGames = 5      #Number of games\n",
    "nSteps = 1000   #Maximum number of steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the env.step output : \n",
    "\n",
    "**'observation'** contains the image tensor for the game ; there might be a possibility to compress this without loss of information (e.g. remove colors). \n",
    "\n",
    "**'reward'** says whether the model did a good thing or not (e.g. it got a block).\n",
    "\n",
    "**'done'** wheter trial is done or not (possibly related to number of lives and blocks)\n",
    "\n",
    "**'info'** Contains the number of lifes left in the current game (within the same env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dead.\n",
      "Episode finished after 302 timesteps \n",
      "\n",
      "Dead.\n",
      "Episode finished after 202 timesteps \n",
      "\n",
      "Dead.\n",
      "Episode finished after 240 timesteps \n",
      "\n",
      "Dead.\n",
      "Episode finished after 170 timesteps \n",
      "\n",
      "Dead.\n",
      "Episode finished after 168 timesteps \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Simulation\n",
    "\n",
    "for i_episode in range(nGames):\n",
    "    observation = env.reset() ;                 #Restarting game\n",
    "    actionSet   = np.random.randint(0,6,nSteps) #Creating random actions ( from [0:5] )  \n",
    "    \n",
    "    for t in range(nSteps):\n",
    "        env.render() #Make sure to turn this off when training, as it is much faster without rendering the game\n",
    "\n",
    "        observation, reward, done, info = env.step(actionSet[t]) #Performing action\n",
    "\n",
    "        if done:\n",
    "            \n",
    "            #If number of life == 0\n",
    "            if not info['ale.lives'] :\n",
    "                print('Dead.')\n",
    "            \n",
    "            print(\"Episode finished after {} timesteps \\n\".format(t+1))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
